batch_size: 1
data_augmentation: {}
data_postprocessing: {}
data_preprocessing:
  test:
    resize:
    - 64
    - 64
  train:
    resize:
    - 64
    - 64
  val:
    resize:
    - 64
    - 64
  inference:
    resize:
    - 64
    - 64
dataloader_config:
  inference:
    drop_last: false
    num_workers: 0
    pin_memory: false
    shuffle: false
  test:
    drop_last: false
    num_workers: 0
    pin_memory: false
    shuffle: false
  train:
    drop_last: false
    num_workers: 0
    pin_memory: false
    shuffle: true
  validation:
    drop_last: false
    num_workers: 0
    pin_memory: false
    shuffle: false
inference_parameters:
  batch_size: 1
  n_images_to_generate: 1
in_memory: false
modality: rad
# compute:
#   precision: "32"
#   # num_devices: 2           # if not set, all GPUs available will be used
#   num_nodes: 2             # if not set, one node will be used
#   strategy: "ddp"        # it is one of ddp, deepspeed, fsdp. can be none, this way it will fallback to the default strategy (DDP if there are more than one GPU, if no gpus are available it will fallback to CPU)
#   strategy_config: {"find_unused_parameters" : True}    # i
model_config:
  architecture:
    num_eval_timesteps: 1
    num_train_timesteps: 1
  converter_type: soft
  labeling_paradigm: unlabeled
  losses:
    name: mse
  model_name: ddpm
  n_channels: 2
  n_dimensions: 2
  norm_type: batch
  optimizers:
      lr: 0.0001
      name: adam
  tensor_shape:
  - 64
  - 64
  schedulers:
    type: triangle
    step_size: 2
num_epochs: 1
patience: 0
save_model_every_n_epochs: 1
verbose: true
version:
  maximum: 0.0.20-dev
  minimum: 0.0.14

batch_size: 1
data_augmentation: {}
data_postprocessing: {}
data_preprocessing: {
  train: {
    'resize': [128, 128],
  },
}
dataloader_config:
  inference:
    drop_last: false
    num_workers: 0
    pin_memory: false
    shuffle: false
  test:
    drop_last: false
    num_workers: 0
    pin_memory: false
    shuffle: false
  train:
    drop_last: false
    num_workers: 0
    pin_memory: false
    shuffle: true
  validation:
    drop_last: false
    num_workers: 0
    pin_memory: false
    shuffle: false
in_memory: false
metrics:
- ncc_min
metrics_config:
  fid:
    features_size: 2048
  lpips:
    converter_type: soft
    net_type: squeeze
    reduction: mean
  ssim:
    reduction: none
modality: rad
model_config:
  amp: false
  architecture:
    discriminator_input_size:
    - 128
    - 128
    generator_output_size:
    - 128
    - 128
    latent_vector_size: 100
  converter_type: soft
  labeling_paradigm: unlabeled
  losses:
    discriminator:
      name: BCELogits
    generator:
      name: BCELogits
  model_name: dcgan
  n_channels: 2
  n_dimensions: 2
  norm_type: batch
  optimizers:
    discriminator:
      betas:
      - 0.5
      - 0.999
      lr: 0.0002
      name: adam
      weight_decay: 0.0
    generator:
      betas:
      - 0.5
      - 0.999
      lr: 0.0002
      name: adam
      weight_decay: 0.0
  schedulers: {}
num_epochs: 1
patience: 0
verbose: true
version:
  maximum: 0.0.20-dev
  minimum: 0.0.14
